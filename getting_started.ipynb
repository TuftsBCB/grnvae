{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "245f02f2-7c5e-4f76-8058-3405c54ab56d",
   "metadata": {},
   "source": [
    "# Getting Started with GRN-VAE\n",
    "\n",
    "This document provides an end-to-end demonstration on how to infer GRN with our implementation of GRN-VAE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757501ef-6bf7-466b-8d47-7b2ebc98e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_beeline\n",
    "from logger import LightLogger\n",
    "from runner import runGRNVAE\n",
    "from evaluate import extract_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32622bc-94b4-4c1c-9e43-fe64a3f74f19",
   "metadata": {},
   "source": [
    "## Model Configurations\n",
    "\n",
    "First you need to define some configs for running the model. We suggest you start with the following set of parameters. The three key concepts proposed in the GRN-VAE paper are controlled by the following parameters. \n",
    "\n",
    "- `delays_on_sparse`: Number of delayed steps on introducing the sparse loss. \n",
    "- `dropout_augmentation`: The proportion of data that will be randomly masked as dropout in each traing step.\n",
    "- `train_on_non_zero`: Whether to train the model on non-zero expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c15b3d-9218-4586-acc8-091bf515111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    # Train/Test split\n",
    "    'train_split': 0.8,\n",
    "    'train_split_seed': None, \n",
    "    \n",
    "    # Neural Net Definition\n",
    "    'hidden_dim': 128,\n",
    "    'z_dim': 1,\n",
    "    'train_on_non_zero': True,\n",
    "    'dropout_augmentation': 0.1,\n",
    "    'cuda': True,\n",
    "    \n",
    "    # Loss\n",
    "    'alpha': 100,\n",
    "    'beta': 1,\n",
    "    'delays_on_sparse': 30,\n",
    "    \n",
    "    # Neural Net Training\n",
    "    'batch_size': 64,\n",
    "    'n_epochs': 250,\n",
    "    'eval_on_n_steps': 10,\n",
    "    'lr_nn': 1e-4,\n",
    "    'lr_adj': 2e-5,\n",
    "    'K1': 1,\n",
    "    'K2': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdda832-f4b7-4758-b1f9-8f7403ba275d",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "[BEELINE benchmarks](https://github.com/Murali-group/Beeline) could be loaded by the `load_beeline` function, where you specify where to look for data and which benchmark to load. If it's the first time, this function will download the files automatically. \n",
    "\n",
    "The `data` object exported by `load_beeline` is an [annData](https://anndata.readthedocs.io/en/stable/generated/anndata.AnnData.html#anndata.AnnData) object read by [scanpy](https://scanpy.readthedocs.io/en/stable/). The `ground_truth` object includes ground truth edges based on the BEELINE benchmark but it's not required for network inference. \n",
    "\n",
    "When you use GRN-VAE on a real world data to discover noval regulatory relationship, here are a few tips on preparing your data:\n",
    "\n",
    "- Read your data using `scanpy.read`. You data should have genes in the column/var and cells in the rows/obs. Transpose your data if it's necessary. \n",
    "- Find out the most variable genes. Unlike many traditional algorithm, GRN-VAE has the capacity to run on large amount of data. Therefore you can set the number of variable genes very high. As described in the paper, we used 5,000 for our Hammond experiment. The only reason why we need this gene filter is to help converge the model.\n",
    "- Normalize your data. A simple log transformation is good enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b34db8-7a88-4e39-8900-f30261dd203c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:15<00:00, 16.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load data from a BEELINE benchmark\n",
    "data, ground_truth = load_beeline(\n",
    "    data_dir='data', \n",
    "    benchmark_data='mDC', \n",
    "    benchmark_setting='500_Non-ChIP'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a2fb83-ddad-47ad-b50d-95ab1b8f7ddf",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Model training is simple with the `runGRNVAE` function. As said above, if ground truth is not available, just set `ground_truth` to be `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e78b34-02c5-4eda-b38a-1f62dc3e94f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = LightLogger()\n",
    "# runGRNVAE initializes and trains a GRNVAE model with the configs specified. \n",
    "vae = runGRNVAE(\n",
    "    data.X, configs, ground_truth=ground_truth, logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ab7b82-2682-4795-9fc3-e4b896224715",
   "metadata": {},
   "source": [
    "## Edge extraction\n",
    "We can extract the adjacency matrix using the `.get_adj()` method. With proper labeling, we can convert the predicted adjacency matrix to an adjacency list in a pandas dataframe using the `extract_edges` function. This table could then be exported using the `.to_csv()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5797d115-9284-4215-906b-2623219c4417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>EdgeWeight</th>\n",
       "      <th>AbsEdgeWeight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H2-EB1</td>\n",
       "      <td>H2-AB1</td>\n",
       "      <td>0.013215</td>\n",
       "      <td>0.013215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H2-AB1</td>\n",
       "      <td>H2-EB1</td>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H2-EB1</td>\n",
       "      <td>H2-AA</td>\n",
       "      <td>0.013155</td>\n",
       "      <td>0.013155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H2-AA</td>\n",
       "      <td>H2-AB1</td>\n",
       "      <td>0.013095</td>\n",
       "      <td>0.013095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H2-AB1</td>\n",
       "      <td>H2-AA</td>\n",
       "      <td>0.013028</td>\n",
       "      <td>0.013028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>H2-AA</td>\n",
       "      <td>H2-EB1</td>\n",
       "      <td>0.012872</td>\n",
       "      <td>0.012872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>H2-EB1</td>\n",
       "      <td>CD74</td>\n",
       "      <td>0.012855</td>\n",
       "      <td>0.012855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>H2-AB1</td>\n",
       "      <td>CD74</td>\n",
       "      <td>0.012717</td>\n",
       "      <td>0.012717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CD74</td>\n",
       "      <td>H2-AA</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>0.012612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>H2-AA</td>\n",
       "      <td>CD74</td>\n",
       "      <td>0.012606</td>\n",
       "      <td>0.012606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Source  Target  EdgeWeight  AbsEdgeWeight\n",
       "0  H2-EB1  H2-AB1    0.013215       0.013215\n",
       "1  H2-AB1  H2-EB1    0.013200       0.013200\n",
       "2  H2-EB1   H2-AA    0.013155       0.013155\n",
       "3   H2-AA  H2-AB1    0.013095       0.013095\n",
       "4  H2-AB1   H2-AA    0.013028       0.013028\n",
       "5   H2-AA  H2-EB1    0.012872       0.012872\n",
       "6  H2-EB1    CD74    0.012855       0.012855\n",
       "7  H2-AB1    CD74    0.012717       0.012717\n",
       "8    CD74   H2-AA    0.012612       0.012612\n",
       "9   H2-AA    CD74    0.012606       0.012606"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = logger.to_df()\n",
    "predicted_A = vae.get_adj()\n",
    "\n",
    "gene_names = data.var_names\n",
    "predicted_edges = extract_edges(A=predicted_A, gene_names=gene_names)\n",
    "predicted_edges.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75188823-d22c-4470-8bd5-520d6f9580a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grn",
   "language": "python",
   "name": "grn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
