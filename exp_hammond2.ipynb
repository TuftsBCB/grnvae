{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b242a682-0557-4789-b1b1-c0b2e2476cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data import load_beeline\n",
    "from logger import LightLogger\n",
    "from runner import runGRNVAE\n",
    "from evaluate import extract_edges, get_metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23de3e96-49f9-4e5e-b8de-82b998ee04ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    # Train/Test split\n",
    "    'train_split': 1.0,\n",
    "    'train_split_seed': None, \n",
    "    \n",
    "    # Neural Net Definition\n",
    "    'hidden_dim': 64,\n",
    "    'z_dim': 1,\n",
    "    'A_dim': 0,\n",
    "    'train_on_non_zero': True,\n",
    "    'dropout_augmentation': 0.1,\n",
    "    'cuda': True,\n",
    "    \n",
    "    # Loss\n",
    "    'alpha': 100,\n",
    "    'beta': 1,\n",
    "    'h_scale': 0,\n",
    "    'delayed_steps_on_sparse': 30,\n",
    "    \n",
    "    # Neural Net Training\n",
    "    'batch_size': 256,\n",
    "    'n_epochs': 1000,\n",
    "    'schedule': [30, 400],\n",
    "    'eval_on_n_steps': 10,\n",
    "    'early_stopping': 0,\n",
    "    'lr_nn': 1e-4,\n",
    "    'lr_adj': 2e-5,\n",
    "    'K1': 1,\n",
    "    'K2': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a0246d3-4ee9-4352-bccf-042908789b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "hammond_dir = 'data/other_data/Hammond_processed/'\n",
    "with open(f'{hammond_dir}/top10000_features_all.txt') as f:\n",
    "    vari_genes = set([x.rstrip() for x in f.readlines()][:5000])\n",
    "\n",
    "data = sc.read(f'{hammond_dir}/male_lpc_data.csv')\n",
    "data = data.transpose()\n",
    "vari_gene_idx = [x in vari_genes for x in data.var_names]\n",
    "data_X = data.X[:, vari_gene_idx]\n",
    "n_obs, n_gene = data_X.shape\n",
    "gene_names = data.var_names[vari_gene_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17257b-3465-492b-9ec3-6ef904023bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/cluster/tufts/slonimlab/hzhu07/miniconda3/envs/grn/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      " 25%|██▍       | 247/1000 [06:46<20:09,  1.61s/it]"
     ]
    }
   ],
   "source": [
    "logger = LightLogger()\n",
    "vae, adjs = runGRNVAE(\n",
    "    data_X, configs, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef55e73-e6fb-47ea-8a1e-13af7c31fd71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grn",
   "language": "python",
   "name": "grn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
